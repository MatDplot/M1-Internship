{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f38a5f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49305665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 10:36:48.276293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-17 10:36:48.276382: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colorbar import Colorbar\n",
    "\n",
    "\n",
    "plt.style.use(['science','ieee'])\n",
    "\n",
    "os.chdir('/home/mathis/Stage M1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73bed5",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63516bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GeV [min,max]\n",
    "\n",
    "M1_range = M2_range = M3_range = [50, 5000]\n",
    "mA_range = [50, 5000]\n",
    "tanB_range = [2, 60]\n",
    "mu_range = [-10**4, 10**4]\n",
    "At_range = Ab_range = Atau_range = [-10**4, 10**4]\n",
    "Mq1L_range = Mq3L_range = [50, 5000]\n",
    "MuR_range = MdR_range = MtR_range = MbR_range = [50, 5000]\n",
    "MeL_range = MtauL_range = MeR_range = MtauR_range = [50, 5000]\n",
    "\n",
    "PMSSM_range_big= [M1_range, M2_range, M3_range, mA_range, tanB_range, mu_range, At_range, Ab_range, \n",
    "              Atau_range, Mq1L_range, Mq3L_range, MuR_range, MdR_range, MtR_range, MbR_range,\n",
    "             MeL_range, MtauL_range, MeR_range, MtauR_range]\n",
    "\n",
    "PMSSM_min = np.array([i[0] for i in PMSSM_range_big])\n",
    "PMSSM_max = np.array([i[1] for i in PMSSM_range_big])\n",
    "\n",
    "PMSSM_sub = np.subtract(PMSSM_max, PMSSM_min)\n",
    "\n",
    "PMSSM_range = [PMSSM_min,PMSSM_max,PMSSM_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd866885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_slha(PMSSM_NN, nom_slha):\n",
    "    f = open(nom_slha, \"w\")\n",
    "    \n",
    "    f.write(\"BLOCK MODSEL \\n\")\n",
    "    f.write(\" 1    0              #MSSM \\n\")\n",
    "    \n",
    "    f.write(\"BLOCK SMINPUTS \\n\")\n",
    "    f.write(\"  1   1.279340000e+02     # alpha^(-1) SM MSbar(M1) \\n\")\n",
    "    f.write(\"  2   1.663700000e-05     # G_Fermi \\n\")\n",
    "    f.write(\"  3   0.1179              # alphas(MS) SM MSbar \\n\")\n",
    "    f.write(\"  4   91.1876             # MZ(pole) \\n\")\n",
    "    f.write(\"  5   4.18                # mb(mb) SM MSbar \\n\")\n",
    "    f.write(\"  6   172.9               # mtop(pole) \\n\")\n",
    "    f.write(\"  7   1.776860000e+00     #m mtau(pole) \\n\")\n",
    "    \n",
    "    f.write(\"BLOCK MINPAR \\n\")\n",
    "    f.write(\"  3   \"+str(PMSSM_NN[4])+\"   #tanb \\n\")\n",
    "    \n",
    "    f.write(\"BLOCK VCKMIN   #CKM param (Wolfenstein) \\n\")\n",
    "    f.write(\"  1   0.22650  #lambda \\n\")\n",
    "    f.write(\"  2   0.790    #A \\n\")\n",
    "    f.write(\"  3   0.141    #rho \\n\")\n",
    "    f.write(\"  4   0.357    #eta \\n\")\n",
    "    \n",
    "    f.write(\"BLOCK EXTPAR \\n\")\n",
    "    f.write(\"  0   \"+str(-1.0)+\"               # Q \\n\")\n",
    "    f.write(\"  1   \"+str(PMSSM_NN[0])+\"        # M1 \\n\")\n",
    "    f.write(\"  2   \"+str(PMSSM_NN[1])+\"        # M2 \\n\")\n",
    "    f.write(\"  3   \"+str(PMSSM_NN[2])+\"        # M3 \\n\")\n",
    "    f.write(\"  11   \"+str(PMSSM_NN[6])+\"       # At \\n\")\n",
    "    f.write(\"  12   \"+str(PMSSM_NN[7])+\"       # Ab \\n\")\n",
    "    f.write(\"  13   \"+str(PMSSM_NN[8])+\"       # Atau \\n\")\n",
    "    f.write(\"  23   \"+str(PMSSM_NN[5])+\"       # Mu \\n\")\n",
    "    f.write(\"  26   \"+str(PMSSM_NN[3])+\"       # Ma \\n\")\n",
    "    f.write(\"  31   \"+str(PMSSM_NN[15])+\"      # MeL \\n\")\n",
    "    f.write(\"  32   \"+str(PMSSM_NN[15])+\"      # MmuL \\n\")\n",
    "    f.write(\"  33   \"+str(PMSSM_NN[16])+\"      # MstauL \\n\")\n",
    "    f.write(\"  34   \"+str(PMSSM_NN[17])+\"      # MeR \\n\")\n",
    "    f.write(\"  35   \"+str(PMSSM_NN[17])+\"      # MmuR \\n\")\n",
    "    f.write(\"  36   \"+str(PMSSM_NN[18])+\"      # MstauR \\n\")\n",
    "    f.write(\"  41   \"+str(PMSSM_NN[9])+\"       # Mq1L \\n\")\n",
    "    f.write(\"  42   \"+str(PMSSM_NN[9])+\"       # Mq2L \\n\")\n",
    "    f.write(\"  43   \"+str(PMSSM_NN[10])+\"      # Mq3L \\n\")\n",
    "    f.write(\"  44   \"+str(PMSSM_NN[11])+\"      # MquR \\n\")\n",
    "    f.write(\"  45   \"+str(PMSSM_NN[11])+\"      # MqcR \\n\")\n",
    "    f.write(\"  46   \"+str(PMSSM_NN[13])+\"      # MqtR \\n\")\n",
    "    f.write(\"  47   \"+str(PMSSM_NN[12])+\"      # MqdR \\n\")\n",
    "    f.write(\"  48   \"+str(PMSSM_NN[12])+\"      # MqsR \\n\")\n",
    "    f.write(\"  49   \"+str(PMSSM_NN[14])+\"      # MqbR \\n\")\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ebbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oracle(logits, PMSSM_range, ratio, succes_path):\n",
    "    \n",
    "    PMSSM_AL = np.add(np.multiply(logits,PMSSM_range[2]),PMSSM_range[0])\n",
    "    \n",
    "    write_slha(PMSSM_AL, \"Advanced NN/AL/pmssm_al.in\")    \n",
    "    \n",
    "    os.system('./SUSY/softsusy-4.1.9/softpoint.x leshouches < Advanced\\ NN/AL/pmssm_al.in > Advanced\\ NN/AL/pmssm_al.out')\n",
    "            \n",
    "          \n",
    "    if os.path.getsize('/home/mathis/Stage M1/Advanced NN/AL/pmssm_al.out') == 0 :\n",
    "        ratio[0]+=1\n",
    "        return 0\n",
    "        \n",
    "    with open('Advanced NN/AL/pmssm_al.out') as slha_out:\n",
    "        content = slha_out.read()\n",
    "        if 'SOFTSUSY problem' in content:\n",
    "            ratio[0]+=1\n",
    "            return 0\n",
    "        if 'LSP # Warning' in content:\n",
    "            ratio[0]+=1\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    ratio[1]+=1\n",
    "    commande = 'mv Advanced\\ NN/AL/pmssm_al.out '\n",
    "    nom_fichier = 'pmssm_al_succes_'+str(ratio[1])+'.out'\n",
    "    os.system(commande+succes_path+nom_fichier)\n",
    "    return 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6553a13",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be63031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               2000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,201\n",
      "Trainable params: 12,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 19)                1919      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,219\n",
      "Trainable params: 32,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 10:36:53.375175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-17 10:36:53.375203: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-17 10:36:53.375222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (MPC): /proc/driver/nvidia/version does not exist\n",
      "2022-06-17 10:36:53.375934: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "path = 'Advanced NN/AL/AL_run/'\n",
    "folder_r = '2022-06-08-08:57:07_II'\n",
    "\n",
    "discriminator = tf.keras.models.load_model(path+folder_r+'/model_II.h5')\n",
    "discriminator.summary()\n",
    "\n",
    "\n",
    "fnc_activation = 'relu'\n",
    "fnc_activation_output = 'sigmoid'\n",
    "inputs = tf.keras.Input(shape=(100,), dtype='float32')\n",
    "x = keras.layers.Dense(100, trainable=True, activation=fnc_activation)(inputs)\n",
    "x = keras.layers.Dense(100, trainable=True, activation=fnc_activation)(x)\n",
    "x = keras.layers.Dense(100, trainable=True, activation=fnc_activation)(x)\n",
    "outputs = keras.layers.Dense(19, activation=fnc_activation_output)(x)\n",
    "generator = tf.keras.Model(inputs,outputs)\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction='sum_over_batch_size')\n",
    "#False pour une probabilité ie [0;1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df54be",
   "metadata": {},
   "source": [
    "# Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24227af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "tf.Tensor(0.49375033, shape=(), dtype=float32)\n",
      "a\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5693361, shape=(), dtype=float32)\n",
      "a\n",
      "Step 3 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5549573, shape=(), dtype=float32)\n",
      "a\n",
      "Step 4 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5277507, shape=(), dtype=float32)\n",
      "a\n",
      "Step 5 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.47455448, shape=(), dtype=float32)\n",
      "a\n",
      "Step 6 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.36281896, shape=(), dtype=float32)\n",
      "a\n",
      "Step 7 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.36898935, shape=(), dtype=float32)\n",
      "a\n",
      "Step 8 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.36521554, shape=(), dtype=float32)\n",
      "a\n",
      "Step 9 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.38783652, shape=(), dtype=float32)\n",
      "a\n",
      "Step 10 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.36101443, shape=(), dtype=float32)\n",
      "a\n",
      "Step 11 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.33660346, shape=(), dtype=float32)\n",
      "a\n",
      "Step 12 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:06<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.3053686, shape=(), dtype=float32)\n",
      "a\n",
      "Step 13 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.29925597, shape=(), dtype=float32)\n",
      "a\n",
      "Step 14 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.3471676, shape=(), dtype=float32)\n",
      "a\n",
      "Step 15 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.39748365, shape=(), dtype=float32)\n",
      "a\n",
      "Step 16 / 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████▋ | 97/100 [00:05<00:00, 18.17it/s]"
     ]
    }
   ],
   "source": [
    "os.system('rm -r Advanced\\ NN/AL/softsusy_succes_IT/')\n",
    "os.system('mkdir -p Advanced\\ NN/AL/softsusy_succes_IT')\n",
    "succes_path_IT = 'Advanced\\ NN/AL/softsusy_succes_IT/'\n",
    "\n",
    "ratio_IT = [0,0]\n",
    "\n",
    "\n",
    "K_size = 100\n",
    "train_step = 250\n",
    "\n",
    "loss_evolution_d = []\n",
    "loss_evolution_g = []\n",
    "\n",
    "for step , i in enumerate(range(train_step)):\n",
    "    print('Step {} / {}'.format(i+1,train_step))\n",
    "    \n",
    "    batch = [[rd.uniform(0,1) for j in range(100)] for k in range(K_size)]\n",
    "    batch = tf.convert_to_tensor(batch)\n",
    "    \n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        logits_g = generator(batch)\n",
    "    \n",
    "        pred_g = []\n",
    "        for j in tqdm(logits_g):\n",
    "            pred = Oracle(j, PMSSM_range, ratio_IT, succes_path_IT)\n",
    "            pred_g.append(pred)\n",
    "    \n",
    "\n",
    "        logits_d = discriminator(logits_g)\n",
    "        \n",
    "        \n",
    "        true = tf.convert_to_tensor([pred_g])\n",
    "        true = tf.transpose(true)      \n",
    "        true_prime = tf.cast(true, dtype=tf.float32)\n",
    "\n",
    "        loss_d = loss_fn(true_prime,logits_d)\n",
    "        loss_evolution_d.append(loss_d)\n",
    "        \n",
    "        gradients_d = tape.gradient(loss_d, discriminator.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients_d, discriminator.trainable_weights))\n",
    "    \n",
    "        #loss_g = loss_d\n",
    "        loss_g = tf.math.abs(tf.math.subtract(1,loss_d))\n",
    "        #loss_g = tf.convert_to_tensor(1-ratio_IT[1]/(ratio_IT[1]+ratio_IT[0]))\n",
    "        print(loss_g)\n",
    "        print('a')\n",
    "        loss_evolution_g.append(loss_g)\n",
    "        \n",
    "        gradients_g = tape.gradient(loss_g, generator.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients_g, generator.trainable_weights))\n",
    "        \n",
    "    \n",
    "print(\"Nombre d'échecs:\",ratio_IT[0])\n",
    "print(\"Nombre de succes:\",ratio_IT[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(train_step)],loss_evolution_d,'ob')\n",
    "plt.plot([i for i in range(train_step)],loss_evolution_g,'or')\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935970d",
   "metadata": {},
   "source": [
    "# Récupération data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94816a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperation_slha(folder,filename,sus_mass,param,succes):\n",
    "    warning = 0\n",
    "    for j in range(succes):\n",
    "        file_name =folder+filename+str(j+1)+'.out' \n",
    "        \n",
    "        with open(file_name) as file:\n",
    "            for indice, ligne in enumerate(file):\n",
    "                if 'tanb' in ligne:\n",
    "                    indice_tanb = indice\n",
    "                \n",
    "                if 'M_1(MX)' in ligne:\n",
    "                    indices_M = [indice+i for i in range(3)]\n",
    "                if 'At(MX)' in ligne:\n",
    "                    indices_A = [indice+i for i in range(3)]\n",
    "                if 'mu(MX)' in ligne:\n",
    "                    indice_mu = indice\n",
    "                if 'mA(pole)' in ligne:\n",
    "                    indice_mA = indice\n",
    "                if 'meL(MX)' in ligne:\n",
    "                    indices_mlL = [indice+i for i in range(3)]\n",
    "                if 'meR(MX)' in ligne:\n",
    "                    indices_mlR = [indice+i for i in range(3)]\n",
    "                if 'mqL1(MX)' in ligne:\n",
    "                    indices_qL = [indice+i for i in range(3)]\n",
    "                if 'muR(MX)' in ligne:\n",
    "                    indices_q = [indice+i for i in range(6)]\n",
    "                    \n",
    "                if 'h0' in ligne:\n",
    "                    indices_higgs = [indice+i for i in range(2)]\n",
    "                if '~g' in ligne:\n",
    "                    indice_g = indice\n",
    "                if '~neutralino(1)' in ligne:\n",
    "                    indices_neutralino = [indice,indice+1,indice+3,indice+4]\n",
    "                if '~d_L' in ligne:\n",
    "                    indices_squarkL = [indice+i for i in range(6)]\n",
    "                if '~d_R' in ligne:\n",
    "                    indices_squarkR = [indice+i for i in range(6)]\n",
    "                if '~chargino(1)' in ligne:\n",
    "                    indices_chargino = [indice,indice+3]\n",
    "        \n",
    "        \n",
    "        file = open(file_name)\n",
    "        lignes = file.readlines()\n",
    "        \n",
    "        for step, i in enumerate(param[0]):\n",
    "            i.append(float(lignes[indices_M[step]].split()[1]))\n",
    "\n",
    "        for step, i in enumerate(param[1]):\n",
    "            i.append(float(lignes[indices_A[step]].split()[1]))  \n",
    "            \n",
    "        param[2].append(float(lignes[indice_mu].split()[1]))\n",
    "        \n",
    "        param[3].append(float(lignes[indice_mA].split()[1]))\n",
    "        \n",
    "        for step, i in enumerate(param[4]):\n",
    "            i.append(float(lignes[indices_mlL[step]].split()[1]))\n",
    "            \n",
    "        for step, i in enumerate(param[5]):\n",
    "            i.append(float(lignes[indices_mlR[step]].split()[1]))\n",
    "            \n",
    "        for step, i in enumerate(param[6]):\n",
    "            i.append(float(lignes[indices_qL[step]].split()[1]))\n",
    "        \n",
    "        for step, i in enumerate(param[7]):\n",
    "            i.append(float(lignes[indices_q[step]].split()[1]))\n",
    "            \n",
    "        param[8].append(float(lignes[indice_tanb].split()[1]))\n",
    "            \n",
    "        \n",
    "        sus_mass[0].append(float(lignes[indice_g].split()[1]))\n",
    "        \n",
    "        for step, i in enumerate(sus_mass[1]):\n",
    "            i.append(float(lignes[indices_neutralino[step]].split()[1]))\n",
    "            \n",
    "        for step, i in enumerate(sus_mass[2]):\n",
    "            i.append(float(lignes[indices_squarkL[step]].split()[1]))\n",
    "\n",
    "        for step, i in enumerate(sus_mass[3]):\n",
    "            i.append(float(lignes[indices_squarkR[step]].split()[1]))\n",
    "        \n",
    "        for step, i in enumerate(sus_mass[4]):\n",
    "            i.append(float(lignes[indices_higgs[step]].split()[1]))\n",
    "\n",
    "        for step, i in enumerate(sus_mass[5]):\n",
    "            i.append(float(lignes[indices_chargino[step]].split()[1]))        \n",
    "    \n",
    "    \n",
    "        with open(file_name) as file:\n",
    "            if 'LSP # Warning' in file.read():\n",
    "                warning+=1\n",
    "    return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add38be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mass = []\n",
    "neutralino_mass = [[] for i in range(4)]   #[N1 , N2 , N3 , N4]\n",
    "squarkL_mass = [[] for i in range(6)]      #[d , u , s , c , b , t]\n",
    "squarkR_mass = [[] for i in range(6)]       \n",
    "higgs_mass = [[] for i in range(2)]        #[h0 , H0]\n",
    "chargino_mass = [[] for i in range(2)]     #[neutralino1 , neutralino2]\n",
    "\n",
    "M_param = [[] for i in range(3)]           #[M1 , M2 , M3]\n",
    "A_param = [[] for i in range(3)]           #[At , Ab , Atau]\n",
    "mu = []\n",
    "mA_param = []\n",
    "mlL_param = [[] for i in range(3)]         #[meL , mmuL , mtauL]\n",
    "mlR_param = [[] for i in range(3)]         #[meR , mmuR , mtauR]\n",
    "mqL_param = [[] for i in range(3)]         #[mqL1 , mqL2 , mqL3]\n",
    "quark_param = [[] for i in range(6)]       #[u , c , t , d , s , b]\n",
    "tanB = []\n",
    "\n",
    "sus_mass = [g_mass,neutralino_mass,squarkL_mass,squarkR_mass,higgs_mass,chargino_mass]\n",
    "param = [M_param,A_param,mu,mA_param,mlL_param,mlR_param,mqL_param,quark_param,tanB]\n",
    "\n",
    "folder = 'Advanced NN/AL/softsusy_succes_IT/'\n",
    "file_name = 'pmssm_al_succes_'\n",
    "warning = recuperation_slha(folder,file_name,sus_mass,param,ratio_IT[1])\n",
    "\n",
    "print('Nombre warning:',warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd25eb",
   "metadata": {},
   "source": [
    "# Sauvegarde Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "folder_name = 'GAN_'+str(date.today())+'-'+str(datetime.now().time().strftime(\"%H:%M:%S\"))\n",
    "commande = 'mkdir -p Advanced\\ NN/AL/AL_run/'+folder_name\n",
    "os.system(commande)\n",
    "\n",
    "with open('Advanced NN/AL/AL_run/'+folder_name+'/config.txt', 'w') as f:\n",
    "    f.write('K: '+str(K_size)+'\\n')\n",
    "    f.write('train steps: '+str(train_step)+'\\n')\n",
    "    f.write(\"Nombre d'échecs: \"+str(ratio_IT[0])+'\\n')\n",
    "    f.write(\"Nombre de succes: \"+str(ratio_IT[1])+'\\n')\n",
    "    f.write(\"Nombre Warning LSP: \"+str(warning)+'\\n')\n",
    "    f.write('\\n')\n",
    "    f.write(\"Fonctions d'activations: \"+fnc_activation+'\\n')\n",
    "    f.write(\"Fonctions d'activations output: \"+fnc_activation_output+'\\n')\n",
    "    f.write('Learning rate:'+str(lr)+'\\n')\n",
    "    f.write('Optimizer: '+str(optimizer)+'\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Generator:')\n",
    "    generator.summary(print_fn=lambda x: f.write(x + '\\n \\n'))\n",
    "    f.write('Discriminator:')\n",
    "    discriminator.summary(print_fn=lambda x: f.write(x + '\\n \\n'))\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Range:')\n",
    "    f.write('M1: '+str(PMSSM_range_big[0])+'\\n')\n",
    "    f.write('M2: '+str(PMSSM_range_big[1])+'\\n')\n",
    "    f.write('M3: '+str(PMSSM_range_big[2])+'\\n')\n",
    "    f.write('mA: '+str(PMSSM_range_big[3])+'\\n')\n",
    "    f.write('tanB: '+str(PMSSM_range_big[4])+'\\n')\n",
    "    f.write('mu: '+str(PMSSM_range_big[5])+'\\n')\n",
    "    f.write('At: '+str(PMSSM_range_big[6])+'\\n')\n",
    "    f.write('Ab: '+str(PMSSM_range_big[7])+'\\n')\n",
    "    f.write('Atau: '+str(PMSSM_range_big[8])+'\\n')\n",
    "    f.write('Mq1L: '+str(PMSSM_range_big[9])+'\\n')\n",
    "    f.write('Mq3L: '+str(PMSSM_range_big[10])+'\\n')\n",
    "    f.write('MuR: '+str(PMSSM_range_big[11])+'\\n')\n",
    "    f.write('dR: '+str(PMSSM_range_big[12])+'\\n')\n",
    "    f.write('MtR: '+str(PMSSM_range_big[13])+'\\n')\n",
    "    f.write('MbR: '+str(PMSSM_range_big[14])+'\\n')\n",
    "    f.write('MeL: '+str(PMSSM_range_big[15])+'\\n')\n",
    "    f.write('MtauL: '+str(PMSSM_range_big[16])+'\\n')\n",
    "    f.write('MeR: '+str(PMSSM_range_big[17])+'\\n')\n",
    "    f.write('MtauR: '+str(PMSSM_range_big[18])+'\\n')\n",
    "    \n",
    "\n",
    "generator.save('Advanced NN/AL/AL_run/'+folder_name+'/generator.h5')\n",
    "discriminator.save('Advanced NN/AL/AL_run/'+folder_name+'/discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48281f",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f388374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histo(title, xlabel, ylabel, list_hist,bins, label, legend = False, histtype='bar', save=False, file_folder=''):\n",
    "    plt.figure()\n",
    "    for indice, hist in enumerate(list_hist):\n",
    "        plt.hist(hist,bins,label=label[indice],histtype=histtype)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend == True:\n",
    "        plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(file_folder)\n",
    "    \n",
    "def subplot_histo(titre, xlabel, ylabel, x, y, share, subtitle, hist_list, label, legend = False, histtype='bar', save=False, file_folder=''):  \n",
    "    fig , ax = plt.subplots(x, y, sharex=share[0], sharey=share[1], constrained_layout = True)\n",
    "    plt.suptitle(titre)\n",
    "    fig.text(0.5, -0.05, xlabel, ha='center')\n",
    "    fig.text(-0.04, 0.5, ylabel, va='center', rotation='vertical')\n",
    "\n",
    "    for indice, hist in enumerate(hist_list): \n",
    "        compteur = 0\n",
    "        for i in range(x):\n",
    "            if y != 1:\n",
    "                for j in range(y):\n",
    "                    ax[i, j].hist(hist[compteur],100,histtype=histtype,label=label[indice])\n",
    "                    ax[i, j].set_title(subtitle[compteur])\n",
    "                    compteur+=1\n",
    "                    if legend == True:\n",
    "                        ax[i, j].legend()\n",
    "            else:\n",
    "                ax[i].hist(hist[compteur],100,histtype=histtype, label=label[indice])\n",
    "                ax[i].set_title(subtitle[compteur])\n",
    "                compteur+=1\n",
    "                if legend == True:\n",
    "                    ax[i].legend()\n",
    "    if save == True:\n",
    "        plt.savefig(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a141f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Advanced NN/AL/AL_run/'+folder_name\n",
    "\n",
    "file = '/histo_gluinos.svg'\n",
    "titre = r'Histogramme de la masse du gluino $\\widetilde{g}$'\n",
    "xlabel = 'Masse (GeV)'\n",
    "ylabel = 'N'\n",
    "plot_histo(titre,xlabel,ylabel,[g_mass],100,['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_neutralinos.svg'\n",
    "titre = 'Histogramme de la masse des neutralinos'\n",
    "subtitle = [r'$\\widetilde{\\chi_1^0}$',r'$\\widetilde{\\chi_2^0}$',r'$\\widetilde{\\chi_3^0}$',r'$\\widetilde{\\chi_4^0}$']\n",
    "share = [False,True]\n",
    "subplot_histo(titre,xlabel,ylabel,2,2,share,subtitle,[neutralino_mass],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_quarksL.svg'\n",
    "titre = 'Histogramme de la masse des quarks L'\n",
    "subtitle = [r'$\\widetilde{d}$',r'$\\widetilde{u}$',r'$\\widetilde{s}$',r'$\\widetilde{c}$',r'$\\widetilde{t}$',r'$\\widetilde{b}$']    \n",
    "subplot_histo(titre,xlabel,ylabel,2,3,share,subtitle,[squarkL_mass],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_quarksR.svg'\n",
    "titre = 'Histogramme de la masse des quarks R' \n",
    "subplot_histo(titre,xlabel,ylabel,2,3,share,subtitle,[squarkR_mass],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_higgs.svg'\n",
    "titre = 'Histogramme de la masse des bosons de Higgs'    \n",
    "subtitle = [r'$h_0$',r'$H_0$']\n",
    "subplot_histo(titre,xlabel,ylabel,2,1,share,subtitle,[higgs_mass],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_charginos.svg'\n",
    "titre = 'Histogramme de la masse des charginos'    \n",
    "subtitle = [r'$\\widetilde{\\chi_1^\\pm}$',r'$\\widetilde{\\chi_2^\\pm}$']\n",
    "subplot_histo(titre,xlabel,ylabel,2,1,share,subtitle,[chargino_mass],['NN'],save=True,file_folder=folder+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/histo_mu.svg'\n",
    "titre = r'Histogramme du paramètre $\\mu$'\n",
    "plot_histo(titre,xlabel,ylabel,[mu],100,['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_mquarks.svg'\n",
    "titre = 'Histogramme des paramètres de masse des quarks'\n",
    "subtitle = [r'$m_{\\widetilde{u_R}}$',r'$m_{\\widetilde{c_R}}$',r'$m_{\\widetilde{t_R}}$',r'$m_{\\widetilde{d_R}}$',r'$m_{\\widetilde{s_R}}$',r'$m_{\\widetilde{b_R}}$']\n",
    "subplot_histo(titre,xlabel,ylabel,2,3,share,subtitle,[quark_param],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_M.svg'\n",
    "titre = 'Histogramme des paramètres de masse'\n",
    "subtitle = [r'$M_1$',r'$M_2$',r'$M_3$']\n",
    "subplot_histo(titre,xlabel,ylabel,3,1,share,subtitle,[M_param],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_A.svg'\n",
    "titre = 'Histogramme des paramètres A'\n",
    "subtitle = [r'$A_t$',r'$A_b$',r'$A_\\tau$']\n",
    "subplot_histo(titre,xlabel,ylabel,3,1,share,subtitle,[A_param],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_mA.svg'\n",
    "titre = r'Histogramme du paramètre $M_A$'\n",
    "plot_histo(titre,xlabel,ylabel,[mA_param],100,['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_mlL.svg'\n",
    "titre = r'Histogramme des paramètres $m_{\\widetilde{f}}$'\n",
    "subtitle = [r'$m_{\\widetilde{e_L}}$',r'$m_{\\widetilde{\\mu_L}}$',r'$m_{\\widetilde{\\tau_L}}$',r'$m_{\\widetilde{e_R}}$',r'$m_{\\widetilde{\\mu_R}}$',r'$m_{\\widetilde{\\tau_R}}$']\n",
    "subplot_histo(titre,xlabel,ylabel,2,3,share,subtitle,[mlL_param+mlR_param],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_mqL.svg'\n",
    "titre = 'Histogramme des paramètres de masse'\n",
    "subtitle = [r'$m_{\\widetilde{q_{1L}}}$',r'$m_{\\widetilde{q_{2L}}}$',r'$m_{\\widetilde{q_{3L}}}$']\n",
    "subplot_histo(titre,xlabel,ylabel,3,1,share,subtitle,[mqL_param],['NN'],save=True,file_folder=folder+file)\n",
    "\n",
    "file = '/histo_tanb.svg'\n",
    "titre = r'Histogramme du paramètre $\\tan \\beta$'\n",
    "plot_histo(titre,xlabel,ylabel,[tanB],100,['NN'],save=True,file_folder=folder+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c92df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Statisique du Neural Network')\n",
    "print(\"Nombre d'échecs:\",ratio_IT[0])\n",
    "print(\"Nombre de succes:\",ratio_IT[1])\n",
    "print('Nombre warning:', warning)\n",
    "print('Éfficacité du AL:',100*ratio_IT[1]/(ratio_IT[0]+ratio_IT[1]),'%')\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
